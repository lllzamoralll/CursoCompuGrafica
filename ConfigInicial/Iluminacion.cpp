• Aprendizaje Supervisado : Deduccion de funciones sobre un grupo de datos(de entrenamiento).Datos de entrada ? Resultados esperados(nominales o numéricos).Objetivo : Crear una funcion que permita predecir el valor resultante de la combinacion de datos de entrada que no están en el conjunto de entrenamiento; partir de la observacion de una serie de eventos o ejemplos. (Complemento de la presentacion) : En el aprendizaje supervisado, los registros se clasifican según un comportamiento futuro predecible o un valor estimado.Se entrena con datos donde el valor de la variable objetivo ya se conoce junto con su informacion historica.Ejemplos : Predecir compras futuras(churn) o productos adquiridos.Algoritmos comunes : Memory Based Reasoning(MBR), K - NN, Árboles de Decision, Redes Neuronales.Métricas : Accuracy, F1 - Score, ROC - AUC.
• Aprendizaje No Supervisado : Método de aprendizaje automático donde el modelo se ajusta a las observaciones, sin conocimiento a priori de variables ortogonales o tipos de memoria aleatoria.Objetivo : Representar el grado de familiaridad o similitud entre la informacion presentada en la entrada.La asociacion o agrupacion es el resultado una vez que se han identificado patrones de entrada.Se deben establecer métodos de similitud entre dos o más variables en asociacion o agrupamiento. (Complemento de la presentacion) : No hay clases predefinidas; se mide similitud con distancias como la euclidiana.Ejemplos: Agrupacion de clientes por patrones sin etiquetas.
• Modelo Predictivo : Registros analizados sobre datos clasificados de acuerdo con un comportamiento futuro predecible o valor futuro estimado.Su medicion se basa en la exactitud de sus predicciones para datos no vistos previamente.Se basa en MDL(Minimum Description Length).Excepciones : Mayor su regla descriptiva.
• Probabilidad y Estadística :
? Poblacion : Conjunto de mediciones tomadas de un universo del que se quieran obtener conclusiones.
? Muestra : Subconjunto representativo de la poblacion.
? Error sistemático : Sesgo(Bias) o la estimacion inmerecida del efecto estudiado a causa de deficiencia en el diseño o ejecucion, relacionado con participantes(sesgo de seleccion) o medicion(sesgo de informacion).
? Tendencia : Cambio ascendente o descendente en datos a lo largo del tiempo.
? Rango : Diferencia entre valor máximo y mínimo de muestras, medida más simple de variabilidad.
? Media aritmética : Valor promedio, calculado como suma de todos los valores x_i dividido entre el número total N.
? Mediana : Valor medio una vez ordenadas las observaciones ascendentemente.
? Moda : Valor que aparece con mayor frecuencia.
? Distribucion : Funcion que asigna probabilidad a cada suceso definido sobre la variable aleatoria.
? Varianza : Medida de variabilidad o dispersion respecto a su media.
§ Poblacional : Calculada como suma de(cada x_i menos la media) ^ 2 dividido entre N.
§ Muestral : Calculada como suma de(cada x_i menos la media) ^ 2 dividido entre n - 1. (Complemento de la presentacion) : Incluye índices como Gini para impureza : Gini(vi) = 1 menos suma de p_j al cuadrado para cada clase j.Y Entropía : E(vi) = menos suma de p_j multiplicado por log base 2 de p_j para cada clase j.Gain : Gain(vi) = impureza de clases menos impureza de vi. (Adicion para el examen - Pregunta 2) : La diferencia entre muestra y poblacion es que la poblacion es el conjunto completo de elementos de interés, mientras que la muestra es un subconjunto seleccionado para inferir características de la poblacion.Media : suma de valores dividido por el número de elementos.Mediana : valor central en datos ordenados.Moda : valor más repetido.
• Naive Bayes : Atributos no tienen contribucion igual al modelo de decision, pero son independientes.
? P_1 = producto de(P_eA1) * (P_eA2) * (P_eA3) * ... * (P_eAn).
? P_2 = producto de(P_eA1') * (P_eA2') * (P_eA3') * ... * (P_eAn').
? P_e1 = P_1 dividido entre(P_1 + P_2).
? P_e2 = P_2 dividido entre(P_1 + P_2).
? Pr(A | B) = [Pr(B | A) multiplicado por Pr(A)] dividido entre Pr(B). (Complemento de la presentacion) : Clasificador bayesiano que asume independencia entre atributos.Usa m - estimate : (c + m * p) dividido entre(n + m).Ejemplo : Decidir "jugar" por clima(pronostico, temperatura).Redes Bayesianas para conocimiento probabilístico. (Adicion para el examen - Pregunta 9) : Para confirmar un pronostico con Naive Bayes, calcula P(Clase | Atributos) = [P(Atributos | Clase) multiplicado por P(Clase)] dividido entre P(Atributos).Usando los datos del examen(9 instancias, 3 Si, 6 No), para el empleado(Estratégico, Excedido, Alta, Con ventas) : Paso 1 : P(Si) = 3 dividido entre 9 = 1 / 3. P(No) = 6 dividido entre 9 = 2 / 3. Paso 2 : P(Estratégico | Si) = 1 dividido entre 3 = 1 / 3. P(Excedido | Si) = 2 dividido entre 3 = 2 / 3. P(Alta | Si) = 3 dividido entre 3 = 1. P(Con ventas | Si) = 2 dividido entre 3 = 2 / 3. P(Atributos | Si) = (1 / 3) * (2 / 3) * 1 * (2 / 3) = 4 dividido entre 27. Paso 3 : P(Estratégico | No) = 3 dividido entre 6 = 1 / 2. P(Excedido | No) = 1 dividido entre 6 = 1 / 6. P(Alta | No) = 3 dividido entre 6 = 1 / 2. P(Con ventas | No) = 1 dividido entre 6 = 1 / 6. P(Atributos | No) = (1 / 2) * (1 / 6) * (1 / 2) * (1 / 6) = 1 dividido entre 144. Paso 4 : P(Atributos) = [4 / 27 multiplicado por 1 / 3] + [1 / 144 multiplicado por 2 / 3] = 4 / 81 + 1 / 216 = 32 / 648 + 3 / 648 = 35 / 648. Paso 5 : P(Si | Atributos) = (4 / 81) dividido entre(35 / 648) = 32 / 35 ˜ 91.43 % .Confirma "Si" con 91.43 % de probabilidad.Razonamiento : Asumimos independencia, calculamos probabilidades condicionales de los datos, aplicamos teorema de Bayes.
• Ejemplo(Naive Bayes) :
	? P_1 = (P_solado) * (P_frio) * (P_alto) * (P_verdealto) * (P_jugar) = (2 / 5) * (1 / 5) * (2 / 5) * (1 / 5) = 2 dividido entre 625.
	? P_2 = (3 / 5) * (1 / 5) * (5 / 5) * (1 / 4) = 3 dividido entre 500.
	? P_e1 = P_1 dividido entre(P_1 + P_2), etc.

	Página 2 (Revisada)
	• Estimador m vía evaluacion probabilística("m-estimate" o m prob.original).
	• kNN a Vecinos más cercanos : Pruebas(c / k) / distancia, modelo predictivo - clasificacion, estimacion de probabilidad, regresion.
	? d(c_k, M_k) = raiz cuadrada de[(x_k menos M_x) al cuadrado + (y_k menos M_y) al cuadrado].Basado en cercanía en distancia, comparado con todos los registros.A ? B(más columnas). (Complemento de la presentacion) : d(k, µ_i) = raiz cuadrada de[(k_x menos µ_ix) al cuadrado + (k_y menos µ_iy) al cuadrado].Útil para clasificacion y regresion. (Adicion para el examen - Pregunta 8) : Para pronosticar con kNN, calcula distancias euclidianas a todos los puntos, selecciona k vecinos más cercanos y toma mayoría.Usando datos numerizados(Proyectos : 5 = Desarrollo, 3 = Estratégico, 1 = Requerimientos; Horas: 100 = Excedido, 75 = Promedio, 25 = Mínimo; Evaluacion: 100 = Alta, 60 = Baja; Ventas: 100 = Con, 20 = Sin).Nuevo punto : [3, 100, 100, 100] .Ejemplo distancia a punto 1[5, 100, 60, 20] : raiz cuadrada de[(3 - 5) al cuadrado + (100 - 100) al cuadrado + (100 - 60) al cuadrado + (100 - 20) al cuadrado] = raiz cuadrada de[4 + 0 + 1600 + 6400] = raiz cuadrada de 8004 ˜ 89.46, clase No.Calculando todas : Vecinos más cercanos(k = 3) : Punto 5[3, 100, 100, 20] distancia raiz cuadrada de[0 + 0 + 0 + 6400] = 80, Si; Punto 9[5, 100, 100, 100] distancia raiz cuadrada de[4 + 0 + 0 + 0] = 2, Si; Punto 2[5, 75, 100, 100] distancia raiz cuadrada de[4 + 625 + 0 + 0] = raiz cuadrada de 629 ˜ 25.08, Si.Mayoría Si.Pronostico: Si.Razonamiento : Normaliza si es necesario(aquí no), ordena distancias, votacion mayoría.
	• Árboles de Decision : Se determinan reglas que describen clases identificadas en la informacion de entrenamiento.Método IR y IR - Random regla.P genera un árbol de decision de un nivel expresado en un formulario que provee un atributo particular.Objetivo : Crear reglas que prueben un solo atributo y abran ramas por valor del atributo.La mejor clasificacion es la que provee la clase más frecuente.Técnica "Divide y Conquista". (Complemento de la presentacion) : Algoritmo recursivo : Seleccionar atributo raiz, dividir en valores válidos / inválidos, repetir hasta pureza.Ejemplo : Ganancia de informacion para atributos como Pronostico(Gain = 0.247).Índices : Gini, Entropía.Reglas : Si Pronostico = Soleado y Humedad = Alta, entonces No Jugar. (Adicion para el examen - Preguntas 5, 6 y 7) : Para identificar nodos, selecciona atributos con mayor gain.Para entropía : E = menos suma de p_j multiplicado por log base 2 de p_j.Gain = E(raíz) menos suma de(tamaño rama / total) multiplicado por E(rama).Usando datos(3 Si, 6 No) : E(raíz) = menos[(3 / 9 multiplicado por log2 de 3 / 9) + (6 / 9 multiplicado por log2 de 6 / 9)] ˜ 0.918.Ejemplo para atributo Proyectos : Desarrollo(2 Si, 2 No) E = 1; Requerimientos(0 Si, 1 No) E = 0; Estratégico(1 Si, 3 No) E ˜ 0.811.Gain = 0.918 menos(4 / 91 + 1 / 90 + 4 / 90.811) ˜ 0.196.Para Evaluacion Cliente : Alta(2 Si, 4 No) E ˜ 0.918; Baja(1 Si, 2 No) E ˜ 0.918.Gain bajo.Mejor nodo : El con mayor gain(e.g., Ventas o Horas).Para Gini : G = 1 menos suma de p_j al cuadrado.Gini(raíz) = 1 menos(3 / 9 al cuadrado) menos(6 / 9 al cuadrado) = 0.444.Ejemplo Proyectos : Gini(Desarrollo) = 0.5; Gini(Requerimientos) = 0; Gini(Estratégico) = 0.375.Gini ponderado = 4 / 90.5 + 1 / 90 + 4 / 90.375 ˜ 0.389.Gain = 0.444 menos 0.389 = 0.055.Mejor nodo : El con mayor gain Gini.Razonamiento : Calcula impureza raíz, impureza ramas, resta ponderada.
	• Reglas de Clasificacion : Algoritmo IR.Para cada atributo : Crear regla que asuma la clase más frecuente, calcular tasa de error, escoger reglas con menor error. (Complemento de la presentacion) : Alternativa a árboles; antecedente(pre - condicion) con operadores Y / O, consecuencia es la clase.
	• Resultado de modelo de Clasificacion : Prediccion de clase o etiqueta / Clasificacion numérica(Score). (Complemento de la presentacion) : Fases : Entrenamiento y Pruebas.Seleccion de caracteristicas : Filtros(Gini), Wrapper, Embebidos.
	• Índice Gini :
? G(Vi) = 1 menos suma de P_k al cuadrado para cada K.
? E(Vi) = suma de P_kj multiplicado por log de P_kj para cada K.
? IV(Vi) = (Prob_clase1) * (Inf_clase1)+... + (Prob_claseN) * (Inf_claseN).
? Gain Gini = Gini(clases) menos Gini(atributo).Ejemplo : Gini(Soleado) = 1 menos(2 / 5 al cuadrado) menos(3 / 5 al cuadrado), etc.

Página 3 (Revisada)
• Redes Neuronales : Modelos de dependencia consisten en identificar un modelo que describe dependencias entre atributos, dicha dependencia es la relacion estadística que involucra dependencia.Correlacion es una amplia clase de relaciones estadísticas que involucran dependencia.
? Cuantitativa o a niveles : Estructural(variables logarítmicamente dependientes usando datos).
• Random Forest : Decision colectiva - M / F o de Ensamble(Bagging) usando múltiples árboles robustos. (Complemento de la presentacion) : Consenso por voto mayoritario(clasificacion) o promedio(regresion).Mejora precision y reduce sobreajuste.
• Regresion :
? Lineal simple / múltiple, polinomica, logística.Objetivos : Expresar la clase como combinacion lineal de atributos + pesos determinantes / aprendizaje o entrenamiento. (Complemento de la presentacion) : y = b0 + b1 * x1 + ... + bn * xn.Minimizar suma de cuadrados de diferencias.Logística para probabilidades(curva sigmoide). (Adicion para el examen - Pregunta 3) : Para identificar la expresion, observa la gráfica : Si es lineal, a) y = b0 + b1 * x1; si curva polinomial, b) y = b0 + b1 * x + b2 * x al cuadrado + ...; si múltiples variables, c).En el examen, la gráfica es curva, por lo que b).
• Agrupacion : Clustering se aplica cuando no hay clases; registros pueden ser divididos en grupos naturales.Dendrogramas.La agrupacion regularmente es seguida por una etapa donde se define un árbol de decision.Distancias: Euclidiana / Manhattan. (Complemento de la presentacion) : K - Means, jerárquica, probabilística.Métricas : Silhouette.
• CRISP - CROSS - Industry Standard Process for Data Mining.Sumarizacion : Herramienta para obtener vision general de la informacion.Reglas de asociacion : Identificar patrones en transacciones. (Complemento de la presentacion) : Fases : Comprension del negocio, datos, preparacion, modelado, evaluacion, despliegue. (Adicion para el examen - Pregunta 10) : Soporte = (transacciones con X y Y) dividido entre total.Confianza = (transacciones con X y Y) dividido entre(transacciones con X).Para una regla e.g. {Estratégico, Excedido, Alta, Con ventas} = > {Si}: Soporte = 0 dividido entre 9 = 0 (no existe instancia exacta); Confianza indefinida.Si la regla es{ Estratégico } = > {Si}: Soporte = 1 dividido entre 9, Confianza = 1 dividido entre 4 = 0.25.Razonamiento : Cuenta instancias que cumplen antecedente y consecuente.
• Market Basket Analysis(MBA) : Análisis de canasta de mercado.Lift = P(A interseccion B) dividido entre[P(A) multiplicado por P(B)]. (Complemento de la presentacion) : Reglas como Pan ? Mantequilla(soporte, confianza, lift).Aplicaciones : Optimizacion de inventario.
• PCA(Análisis de Componentes Principales) : Simplifica datos transformando variables en componentes que capturan máxima varianza. (Complemento de la presentacion) : Reduce dimensionalidad; primeros CPs explican% de varianza.Ejemplo: Reducir 50 variables a 5 CPs(92 % varianza).
• Validacion y Mejora del Modelo : Train - test, validacion cruzada, bootstrapping.Tuning hiperparámetros(Grid Search, Bayesian Optimization). (Complemento de la presentacion) : Tabla comparativa : Predictivos(Accuracy, RMSE) vs.Descriptivos(Silhouette, Davies - Bouldin).
•(Adicion para el examen - Pregunta 1) : Clasificacion de modelos : Supervisado(Random Forest, Decision Tree, SVM, Regresion Lineal, Multivariada, Perceptron, Naive Bayes, K - Nearest, Regresion Polinomial); No Supervisado(PCA, K - Means, Reglas de asociacion, Agrupacion / Clustering); Semi Supervisado(Self - Training, Label Spreading); A priori(para reglas de asociacion); Redes Neuronales(Perceptron como base); Machine Learning(general).
•(Adicion para el examen - Pregunta 4) : Funcion discriminante lineal : Para separar clases A y B, encuentra la línea equidistante a las rectas dadas(Azul : y = 0.3 + 0.65x; Roja: y = -0.64 + 1.6x).Usando formula de bisector : Líneas L1 = 0.65x - y + 0.3 = 0, L2 = 1.6x - y - 0.64 = 0. Bisector interna ˜ y = -0.984x + 1.916 (o la externa y = 4.52x + 1.916, seleccionar la que separa clusters).Clasifica punto(x, y) : Si por encima de la línea, clase A; debajo, B.Razonamiento: Normaliza líneas, resuelve L1 / norm1 = ± L2 / norm2, elige bisector que maximiza separacion.
•(Adicion para el examen - Pregunta 5) : Los 4 principales nodos(atributos para splits) : Basado en gain, prioriza Ventas(alta impureza reduccion), Evaluacion Cliente, Horas cursadas, Proyectos.Ilustracion : Raíz ? Ventas(rama Con / Si, Sin / No); luego Evaluacion, etc.
